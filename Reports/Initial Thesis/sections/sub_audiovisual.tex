\documentclass[../initial_thesis.tex]{subfiles}

\begin{document}
\section{Audiovisual Expression}
\subsection{Early practitioners}
There are two animators whose works emphasise the relations between music and visual expression -- Norman McLaren and John Whitney. McLaren used the term ``animated sound'' to explain how, by painting in the audio tracks of film strips, one is able to synthesize audio \cite{McLaren1953}. In documenting his methods of synthesizing sound, McLaren mapped the shapes of his drawings to the qualities of the sounds they produced \cite{McLaren1953}. Whitney, on the other hand, focused his works and research on how to recreate the tension and release of music through visuals. In his book, \textit{Digital Harmony}, Whitney draws parallels between music and structured visual movements \cite{Whitney1980}. He envisions ``a visual world of harmony to which there must be innate human responses, just as in the world of music'' --- arguing that certain forms of motion elicit emotional responses in the same way that harmony and disharmony in music does \cite{Whitney1980}. About a decade later, when advances in technology allowed for algorithmically designed graphics-generating capabilities on personal computers, Whitney restated his argument that the parallels between music and certain visual patterns can come together to create something greater than its parts \cite{Whitney1991}. Crucially, Whitney believes that ``only \textbf{structured} motion begets emotion'' \cite{Whitney1980} and that the architecture of music is embodied by algorithmic resonance and ratio \cite{Whitney1991}. These are operations that computers are particularly adept at performing. \par

\subsection{Concepts of \textit{Audio-Vision}}
Michel Chion coined the term ``audio-vision'' in his 1994 book, \textit{Audio-Vision}, to describe the specific mode of reception that audiovisual media places viewers in \cite{Chion1994}. In \textit{Audio-Vision}, Chion attempts to ``demonstrate the reality of audiovisual combination --- that one perception of influences the other and transforms it'' \cite{Chion1994}. Chion also introduces the concept of the ``audiovisual contract'' to explain how viewers think of sound and image as forming a single entity, when they are in reality two separate objects \cite{Chion1994}. While Chion's work was primarily directed at sound on film, the concepts he introduced continue to inform and influence contemporary researchers and practitioners of audiovisual expression. What follows is a non-exhaustive list of the concepts that Chion introduces in his book to describe how sound relates to image.

\paragraph{Added value} Chion uses the term ``added value'' to describe the way in which sound enriches an image by providing it with expressive and informative value --- thereby creating the impression that the value perceived from the combination of sound and image was inherent in the image itself \cite{Chion1994}.

\paragraph{Synchresis} A portmanteau of the words ``synchronism'' and ``synthesis''. It refers to the viewer's ability to form an association between what is seen and what is heard, even if the sounds were not actually made by the visuals \cite{Chion1994}. Foley artists are able to create sound effects using non-literal recordings of what is shown on screen due to this principle. According to Chion, synchresis is organised by gestaltist principles explaining how humans perceive a whole from the sum of its parts \cite{Chion1994}.

\paragraph{Causal, Semantic, and Reduced Listening} Chion states that there are three modes of listening: Causal, Semantic, and Reduced listening \cite{Chion1994}. All three modes are named with reference to the goal of the listener. Causal listening is listening with the intention of discerning its source or cause. Semantic listening refers to listening to understand some kind of message conveyed through sound. Reduced listening refers to listening to a sound for its inherent traits, rather than as a medium to transmit other information. \par

Chion's \textit{Audio-Vision} provides us with a basis of concepts and terms to describe the field of audiovisual expression. His work identifies and explains the various factors that influence how sound and image come together and how that combination influences the way the audience perceives audiovisual media. It also gives us the impetus and techniques to design visuals that pair with audio, which is the primary function of the video synthesizer being implemented in this project.

\subsection{Contemporary artists and researchers} % mention artists like Ryoji Ikeda
Contemporary researchers like Adriana Sa build upon the concepts introduced by Chion. Sa's research on ``fungible audio-visual mapping'' examines how audiovisual artists can design visuals in a manner that prevents their music from being overshadowed by accompanying visuals \cite{Sa2014}. Sa's research references Chion's concept of synchresis --- that viewers have the ability to form a causal relationship between the sounds they hear and the visuals they see. Her work proposes means of thresholding the causal relationship between the audio and the visual in order to prevent the visual sensorial experience from distracting from the sonic qualities of the piece \cite{Sa2013}. Sa's research is ultimately concerned with keeping the viewer in a state of reduced listening in spite of the accompanying visuals, so that their focus remains on the sounds themselves rather than their potential sources. \par

Michael Kubovy and Michael Schutz are two other contemporary researchers whose works respond to the concepts introduced in \textit{Audio-Vision}. Kubovy and Schutz use the terms '``where'' and ``what'' subsystems' to describe the differing ways in which hearing and seeing allow us to locate things in space and recognise things \cite{Kubovy2010}. Their work focuses on how the ``where'' and ``what'' subsystems of sight bind to the ``what'' subsystem of audition to form a single audio-visual object \cite{Kubovy2010}. Crucially, their work identifies conditions where the binding of visual to audio fail and disprove Chion's theory that synchrony between audio and visual are always the most important factors in establishing a cause-effect relationship. \par

Ryoji Ikeda, on the other hand, is a prominent example of a contemporary audiovisual practitioner. One of his works, \textit{test pattern}, consists of a program that ``converts audio signal patterns into tightly synchronised barcode patterns on screen'' \cite{Ikeda}. The effect of this can be seen in Figure \ref{fig:testpattern}. Ikeda's works provide us with many examples of how pairing audio with visual stimuli can produce compelling art pieces. \par

\begin{figure}[h]
  \includegraphics[scale = 0.5]{Report2/testpattern}
  \centering
  \caption{Photo of performance of \textit{test pattern} \cite{Ikeda}}
  \label{fig:testpattern}
\end{figure}

% Point out how studies have contradicted Chion's writings on verisimilitude being secondary to synchrony
The works of McLaren and Whitney established the links between the audio and visual realms while Chion's writings introduced the concepts of how the interaction between sounds and visuals can affect the perceptions of the viewer. More recent research by Sa builds upon the works of Chion by applying and refining the concepts he introduces in audiovisual practice while Kubovy and Schutz challenge Chion's concepts and continue studies into how we establish relationships between audio and visual. These works fuel the motivations behind implementing a video synthesizer that visualises sound. The video synthesizers explored in Section \ref{sec:vsynths}, could thus be seen as tools for audiovisual expression --- built to provide its users with the means to invoke the ``added value'' from having sound and video interact. Music and visuals can come together to create an experience that is more than the sum of its parts and this provides an impetus to the creation of video synthesizers made specifically to accompany an audio input. \par

In order to implement a video synthesizer that reacts to audio signals, it is important to understand the various methods with which we are able to extract music features from an audio signal. The following section will introduce some of the techniques from the field of MIR that will be used to extract useful information from an audio signal in real time.
% Talk about gap of what people have done
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../initial_thesis"
%%% End:
