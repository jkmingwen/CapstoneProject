\documentclass[../initial_thesis.tex]{subfiles}

\begin{document}
\section{Initial candidates} \label{sec:initialcandidates}
Sa argues in \textit{How An Audio-Visual Instrument Can Foster The Sonic Experience} that ``creating fungible rather than consistently transparent correspondencies between sounds and visual events'' is one of the key principles to fostering an emphasis on sound in an audio-visual experience \cite{Sa2013}. She also argues that ``sonic complexity can be fully experienced...[when] the demand for visual processing is low'' \cite{Sa2013}. She therefore advocated for two things in relation to designing visuals: (1) visuals with complex and inconsistent mappings to an audio input, and (2) visuals that minimized drastic changes and divergent movements \cite{Sa2013}. These principles were directed towards designing an audio-visual instrument that specifically avoided obfuscating the audio aspects of an audiovisual performance by designing visuals that directed attention towards the accompanying audio. The goal of the video synthesizer is to try to produce a sense of \emph{added value} from having audio and visuals interact, as defined by Chion \cite{Chion1994}. This might not always involve regulating the attention of the viewer on the visual aspect of the performance. Therefore, in order to provide a range of audio-visual experiences from the video synthesizer, three different animations were designed with increasing levels of complexity in audio to visual mappings and movements. The complexity of each animation was influenced by two characteristics: points of focus and axes of movement. Each animation was designed with a different permutation of these two aspects. The first has a single point of focus in the middle of the screen with movements solely along the y-axis. The second also has a single point of focus, but whose elements move independently across both x and y-axes. The third has multiple points of focus, with movements along both the x and y-axis. For ease of reference, they have been named according to their characteristic shape or movements: Circles, Clouds, and Shimmer respectively.

\subsection{Circles}
Circles is made up of a series of ellipses placed adjacent to one another in a horizontal line in the middle of the screen. Each ellipse corresponds to a sample in the buffer. It is based off the visualisation of an audio signal that was first implemented in Section \ref{sec:openframeworks}. The mapping of each sample's amplitude to its corresponding ellipse's displacement along the y-axis, as well as overall volume to radius of the ellipses, remains the same. The design of this animation was inspired by Chion's writing on temporalising an image with sound, where he states that ``A smooth and continuous sound is less animating than an uneven or fluttering one'' \cite{Chion1994}. As seen in Figure \ref{fig:circles1}, by mapping the amplitude of each sample to the displacement of an ellipse along the y-axis, Circles is able to visualise a smooth sound with a wave with regular peaks and troughs and a more complex sound with a correspondingly complex wave shape. The mapping of volume to the radii of the ellipses emphasises the regularity or irregularity of the waveform. This animation directly contradicts Sa's principles for designing visuals, as mentioned in Section \ref{sec:initialcandidates}: the mapping from audio to visuals are transparent and consistent and the visuals are full of drastic changes with divergent movements.

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width = 0.9\linewidth]{Survey/circles_complexsoft}
    \caption{Complex but soft sound}
  \end{subfigure} 
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width = 0.9\linewidth]{Survey/circles_simpleloud}
    \caption{Simple but loud sound}
  \end{subfigure}
  \caption{Circles reacting to an audio signal}
  \label{fig:circles1}
\end{figure}

\subsection{Clouds}
Clouds is based on Konstantin Makhmutov's algorithm in \textit{Wobbly Swarm} \cite{Makhmutov}. His algorithm forms the basis for a particle cloud in which each particle, represented by an ellipse, experiences an attractive force to every other particle on the screen until they cross a certain threshold of distance --- after which, they experience a repulsive force pushing them away from one another. Here, the volume of the audio signal has been mapped to amplify the force enacted on the particle by the other particles. The amplification of force is also visualised by a temporary increase in the radius of the ellipse. The effect of this mapping can be seen in Figure \ref{fig:clouds1}. In contrast to Circles, Clouds features elements whose movements are not entirely dependent on the audio signal. The elements aren't fixed to a specific point on the x-axis or y-axis either. They thus form a more dynamic and unpredictable audio to visual mapping compared to Circles. The decision to include movements in the animation that were independent of the audio signal was primarily informed by Sa's research. As she states in her paper, ``With a fungible audio-visual mapping, perception continues to acknowledge conflicting information, embracing convergences and divergences as inconclusive concepts'' \cite{Sa2014}. Her research showed that causation can be sensed in an audio-visualisation even when it is unclear how the audio affects the visuals. 

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width = 0.9\linewidth]{Survey/clouds_soft}
    \caption{Soft sound}
  \end{subfigure} 
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width = 0.9\linewidth]{Survey/clouds_loud}
    \caption{Loud sound}
  \end{subfigure}
  \caption{Clouds reacting to an audio signal}
  \label{fig:clouds1}
\end{figure}

\subsection{Shimmer}
Shimmer is made up of an array of lines that spin about fixed points to form ripple effects that slowly spread out across the screen, as seen in Figure \ref{fig:shimmer1}. The angle of each line's rotation is determined by a Perlin Noise function that is increasingly offset with each element. Perlin Noise is also used to determine the alpha value, which affects the opacity of each line. The volume of the audio signal determines the speed of the rotation. It is distinct from the other two animations as there are multiple points of interest for the viewer to focus on --- all elements are spread across the screen and are constantly in motion. This animation was an attempt to adhere to Sa's principles for designing visuals, as mentioned in \ref{sec:initialcandidates}. Drastic changes in the visuals are limited and the mapping from audio to visual is less clear in comparison the other two audio-visualisations.

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width = 0.9\linewidth]{Survey/shimmer1}
    \caption{Initial shape}
  \end{subfigure} 
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width = 0.9\linewidth]{Survey/shimmer2}
    \caption{After a few moments}
  \end{subfigure}
  \caption{Shimmer reacting to an audio signal}
  \label{fig:shimmer1}
\end{figure}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../initial_thesis"
%%% End: